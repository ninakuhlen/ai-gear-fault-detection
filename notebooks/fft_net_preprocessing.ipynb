{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Projekt: Fehlererkennung in Getrieben**\n",
    "## Netztyp 2: FFT-Net\n",
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Vorbereitung**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from uuid import uuid4\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# module imports from /src\n",
    "if Path.cwd().stem == \"notebooks\":\n",
    "    os.chdir( Path.cwd().parent)\n",
    "    \n",
    "import src.preprocessing as pre\n",
    "import src.data_loader as dl\n",
    "import src.visualization as vis\n",
    "import src.model_constructor as mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# boolean values to control the program flow\n",
    "TESTING: bool = False\n",
    "DOWNLOAD: bool = False\n",
    "SHOW: bool = False\n",
    "\n",
    "# setup a single index for control of preprocessing steps\n",
    "CONTROL_INDEX: int = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a unique identifier for this run\n",
    "UUID: str = str(uuid4())\n",
    "\n",
    "print(f\"Current UUID:\\t{UUID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of CPU cores:\t\t12\n",
      "Number of GPUs available:\t0\n"
     ]
    }
   ],
   "source": [
    "# setup system and check the number of cpu cores and gpus available\n",
    "mc.system_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Laden der Datensätze**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOWNLOAD:\n",
    "    \n",
    "    # download full dataset from kaggle\n",
    "    dl.fetch_kaggle_dataset(dl.DATASET_ADDRESS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "READING DEVELOPMENT DATA\n",
      "0D.csv successfully loaded.\n",
      "1D.csv successfully loaded.\n",
      "2D.csv successfully loaded.\n",
      "3D.csv successfully loaded.\n",
      "4D.csv successfully loaded.\n",
      "READING EVALUATION DATA\n",
      "0E.csv successfully loaded.\n",
      "1E.csv successfully loaded.\n",
      "2E.csv successfully loaded.\n",
      "3E.csv successfully loaded.\n",
      "4E.csv successfully loaded.\n",
      "READING COMPLETED\n"
     ]
    }
   ],
   "source": [
    "if not TESTING:\n",
    "    \n",
    "    # load data from folder and split in training and evaluation data\n",
    "    data_path = Path().cwd() / \"data\" / \"raw\"\n",
    "    development_data, evaluation_data = dl.load_all_datasets(data_path)\n",
    "    all_datasets = development_data + evaluation_data\n",
    "\n",
    "else:\n",
    "\n",
    "    # program testing set\n",
    "    test = dl.load_dataset(Path(\"./data/raw/1D.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW:\n",
    "    if not TESTING:\n",
    "        for index, dataset in enumerate(all_datasets):\n",
    "            # visualize one random dataset for data validation\n",
    "            print(dataset.attrs[\"path\"])\n",
    "            vis.plot_columns_as_subplots(dataset, dataset.columns)\n",
    "\n",
    "    else:\n",
    "\n",
    "        # visualize the program testing set\n",
    "        vis.plot_columns_as_subplots(test, test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Preprocessing**\n",
    "\n",
    "##### **Bereinigung der Daten**\n",
    "Jeder Datensatz beginnt mit negativen Spitzen in den V_in und den Measured_RPM. Tresholding einer der beiden Messreihen entfernt diese Fehler im jeweiligen Datensatz. Durch Anpassung der Indizes beginnt jeder Datensatz mit Index 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12288 rows discarded.\n",
      "Limits interpreted as integers.\n",
      "37712 rows discarded.\n",
      "12288 rows discarded.\n",
      "Limits interpreted as integers.\n",
      "37712 rows discarded.\n",
      "12288 rows discarded.\n",
      "Limits interpreted as integers.\n",
      "37712 rows discarded.\n",
      "12288 rows discarded.\n",
      "Limits interpreted as integers.\n",
      "37712 rows discarded.\n",
      "12288 rows discarded.\n",
      "Limits interpreted as integers.\n",
      "37712 rows discarded.\n",
      "12288 rows discarded.\n",
      "Limits interpreted as integers.\n",
      "37712 rows discarded.\n",
      "12288 rows discarded.\n",
      "Limits interpreted as integers.\n",
      "37712 rows discarded.\n",
      "12288 rows discarded.\n",
      "Limits interpreted as integers.\n",
      "37712 rows discarded.\n",
      "12288 rows discarded.\n",
      "Limits interpreted as integers.\n",
      "37712 rows discarded.\n",
      "12288 rows discarded.\n",
      "Limits interpreted as integers.\n",
      "37712 rows discarded.\n"
     ]
    }
   ],
   "source": [
    "if not TESTING:\n",
    "\n",
    "    measurement_cycles = []\n",
    "\n",
    "    for index, dataset in enumerate(all_datasets):\n",
    "        pre.apply_threshold(dataset, threshold=0, column=\"V_in\", mode=\"le\", reset_index=False)\n",
    "        dataset = pre.discard_data(dataset, end=50_000, reset_index=True)\n",
    "        subsets = pre.split_by_gradient_direction(dataset, column=\"V_in\", reset_index=True)\n",
    "        for subset in subsets:\n",
    "            measurement_cycles.append(subset)\n",
    "        \n",
    "else:\n",
    "    \n",
    "    pre.apply_threshold(test, threshold=0, column=\"V_in\", mode=\"le\", reset_index=False)\n",
    "    test = pre.discard_data(test, end=50_000, reset_index=True)\n",
    "    test_measurement_cycles = pre.split_by_gradient_direction(test, column=\"V_in\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW:\n",
    "    if not TESTING:\n",
    "\n",
    "        # visualize one random dataset for data validation\n",
    "        for dataset in measurement_cycles:\n",
    "            print(dataset.attrs[\"path\"])\n",
    "            vis.plot_columns_as_subplots(dataset,\n",
    "                                        dataset.columns)\n",
    "\n",
    "        \n",
    "    else:\n",
    "        for dataset in test_measurement_cycles:\n",
    "            # visualize the program testing set\n",
    "            print(dataset.attrs[\"path\"])\n",
    "            vis.plot_columns_as_subplots(dataset, dataset.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Fast Fourier Transformation**\n",
    "Eine Fast Fourier Transformation (FFT) über führt die Daten eines ausgewählten Sensors vom Zeit- in den Frequenzbereich. Sie verwendet ein Fenster von einer Sekunde bzw. $n=4096$ Messwerten. Mey et al. verwenden in ihrer Arbeit die ersten 2048 Fourier-Koeffizienten. Diese sind der *Zero Frequency Term* bei $0 \\times f_s$, die Summe des Signals, und die 2048 positiven Frequenzanteile (*frequency components*). NumPy bietet zur Berechnung der positiven Frequenzanteile die *Real FFT* numpy.rfft(), die in diesem Projekt implementiert ist. Pro Sekunde des ursprünglichen Datensatzes generiert die FFT somit 2048 Frequenzanteile. Aufgrund der Halbierung der Anzahl von Messwerten, speichert ein neues Dataset die Fourier-Koeffizienten. \n",
    "\n",
    "$$A_k = \\frac{1}{n} \\cdot \\sum^{n-1}_{m=0} a_m \\cdot e^{-2\\,\\pi\\,i\\,\\frac{m\\,k}{n}} \\qquad \\text{mit} \\qquad a_m = e^{2\\,\\pi\\,i\\,m\\,f\\,\\Delta t} \\quad \\text{und} \\quad k = 0,~\\dots,~n-1$$\n",
    "\n",
    "Für eine spätere Zuordnung wird mit derselben Fenstergröße der Median der Drehzahlen berechnet. Das Label des ursprünglichen Datensatzes wird in das neue Dataset übertragen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SENSOR: int = 1\n",
    "\n",
    "if not TESTING:\n",
    "\n",
    "    for index, dataset in enumerate(measurement_cycles):\n",
    "        # calculate fft frequencies and magnitudes alongside the median rpms\n",
    "        fft_dataset = pre.calculate_fft_magnitudes(dataset, column=f\"Vibration_{SENSOR}\", normalize=False)\n",
    "        rpms = pre.median(dataset, column=\"Measured_RPM\", stretch=True)\n",
    "        fft_dataset[\"rpm\"] = rpms[::2]\n",
    "        measurement_cycles[index] = fft_dataset\n",
    "\n",
    "else:\n",
    "    \n",
    "    for index, dataset in enumerate(test_measurement_cycles):\n",
    "        fft_data = pre.calculate_fft_magnitudes(dataset, column=f\"Vibration_{SENSOR}\", normalize=False)\n",
    "        rpms = pre.median(dataset, column=\"Measured_RPM\", stretch=True)\n",
    "        fft_data[\"rpm\"] = rpms[::2]\n",
    "        test_measurement_cycles[index] = fft_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW:\n",
    "    if not TESTING:\n",
    "\n",
    "        # describe one random dataset for data validation\n",
    "        display(measurement_cycles[CONTROL_INDEX].describe())\n",
    "        vis.plot_fft_spectrogram(data_frame=measurement_cycles[CONTROL_INDEX],\n",
    "                                    figsize=(14, 6))\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # program testing set\n",
    "        for dataset in test_measurement_cycles:\n",
    "            display(dataset.describe())\n",
    "            vis.plot_fft_spectrogram(data_frame=dataset,\n",
    "                                    figsize=(14, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Robust Scaling**\n",
    "\n",
    "Robust Scaling entfernt aus der Messreihe $X$ \n",
    "\n",
    "Interquantilabstand (*Inter-Quantile Range*, IRQ) zwischen dem 5%-Quantil $x_{0.05}$ und dem 95%-Quantil $x_{0.95}$.\n",
    "\n",
    "$$x^*_i = \\frac{x_i - \\text{median}~{X}}{x_{0.95} - x_{0.05}} \\qquad \\text{mit} \\qquad X=\\{x_0,~x_1,~\\dots,~x_n-1\\}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not TESTING:\n",
    "\n",
    "    for index, dataset in enumerate(measurement_cycles):\n",
    "        measurement_cycles[index] = pre.scale_robust(dataset, column=\"fft_magnitude\")\n",
    "\n",
    "else:\n",
    "    for index, dataset in enumerate(test_measurement_cycles):\n",
    "        scaled_data = pre.scale_robust(dataset, column=\"fft_magnitude\")\n",
    "        test_measurement_cycles[index] = scaled_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHOW:\n",
    "    if not TESTING:\n",
    "\n",
    "        # describe one random dataset for data validation\n",
    "        display(measurement_cycles[CONTROL_INDEX].describe())\n",
    "        vis.plot_fft_spectrogram(data_frame=measurement_cycles[CONTROL_INDEX],\n",
    "                                    figsize=(14, 6))\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # program testing set\n",
    "        for dataset in test_measurement_cycles:\n",
    "            display(dataset.describe())\n",
    "            vis.plot_fft_spectrogram(data_frame=dataset,\n",
    "                                    figsize=(14, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0D_0_fft.csv successfully saved.\n",
      "0D_1_fft.csv successfully saved.\n",
      "1D_0_fft.csv successfully saved.\n",
      "1D_1_fft.csv successfully saved.\n",
      "2D_0_fft.csv successfully saved.\n",
      "2D_1_fft.csv successfully saved.\n",
      "3D_0_fft.csv successfully saved.\n",
      "3D_1_fft.csv successfully saved.\n",
      "4D_0_fft.csv successfully saved.\n",
      "4D_1_fft.csv successfully saved.\n",
      "0E_0_fft.csv successfully saved.\n",
      "0E_1_fft.csv successfully saved.\n",
      "1E_0_fft.csv successfully saved.\n",
      "1E_1_fft.csv successfully saved.\n",
      "2E_0_fft.csv successfully saved.\n",
      "2E_1_fft.csv successfully saved.\n",
      "3E_0_fft.csv successfully saved.\n",
      "3E_1_fft.csv successfully saved.\n",
      "4E_0_fft.csv successfully saved.\n",
      "4E_1_fft.csv successfully saved.\n"
     ]
    }
   ],
   "source": [
    "# saving the preprocessed data\n",
    "if not TESTING:\n",
    "\n",
    "    for dataset in measurement_cycles:\n",
    "        dl.save_dataset(dataset, uuid=UUID)\n",
    "\n",
    "else:\n",
    "    for dataset in test_measurement_cycles:\n",
    "        dl.save_dataset(dataset, uuid=UUID)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
