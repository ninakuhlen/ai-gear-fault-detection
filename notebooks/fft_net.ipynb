{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Projekt: Fehlererkennung in Getrieben**\n",
    "## Netztyp 2: FFT-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Vorbereitung**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# module imports from /src\n",
    "if Path.cwd().stem == \"notebooks\":\n",
    "    os.chdir( Path.cwd().parent)\n",
    "\n",
    "import src.data_loader as dl\n",
    "import src.visualization as vis\n",
    "import src.net_models as net\n",
    "import src.input_preparation as ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beispiel für ein Diagramm im Markdown\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    Start --> Stop\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the source directory for the preprocessed data to use\n",
    "SOURCE: str = \"f2fcf2aa-bd96-4d89-8bb5-4a0a1bc11b1b\"\n",
    "\n",
    "# setup a single index for control purposes\n",
    "CONTROL_INDEX: int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup system and check the number of cpu cores and gpus available\n",
    "net.system_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Laden der Datensätze**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Üblicherweise werden für das Training eines neuronalen Netzes mittels Supervised Learning die Daten in mindestens zwei separate Datensätze aufgeteilt: einen Trainings- und einen Testdatensatz. Mit dem Testdatensatz können nach dem Training zukünftige (dem Netz unbekannte) Dateneingaben simuliert werden und so vorab die Zuverlässigkeit des Trainings beurteilt werden (Liu, 2025, S. 39).\n",
    "Nach dem Laden der Daten aus dem *data*-Ordner werden CSV-Dateien mit der Endung *D* in der Liste *development_data* und Dateien mit der Endung *E* in der Liste *evaluation_data* gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from folder and split in training and evaluation data\n",
    "data_path = Path().cwd() / \"data\" / \"processed\" / SOURCE\n",
    "development_data, evaluation_data = dl.load_all_datasets(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplarisch wird ein Datensatz aus den Development-Daten in mehreren Subplots visualisiert, um sicherzustellen, dass die Daten korrekt geladen wurden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize one random dataset for data validation\n",
    "vis.plot_column_data(development_data[CONTROL_INDEX],\n",
    "                             development_data[CONTROL_INDEX].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Vorbereitung der Daten zur Eingabe in das neuronale Netz**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um das neuronale Netz trainieren zu können, ist eine Aufbereitung der Trainings- und Testdaten erforderlich.\n",
    "Dazu werden die einzelnen DataFrames mit den Trainingsdaten zu einem einheitlichen DataFrame zusammengeführt. Gleichzeitig wird eine zusätzliche Spalte *Label* erstellt, welche die gemessenen Unwuchtstärken (*none*, *slight*, *moderate*, *significant* und *strong*) enthält und somit als *Output* für die spätere Klassifizierung dient (Liu, 2025, S.19). Die Labels werden in das One-Hot-Encoding-Format überführt, welches für die Multiklassen-Klassifizierung in Deep-Learning-Systemen benötigt wird (Liu, 2025, S.74).\n",
    "Anschließend werden die DataFrame-Spalten mit den Amplituden der Vibrationen als *Input* (Features) für das NN spezifiziert.\n",
    "\n",
    "(If Bedingung Binary Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_development_dataset = ip.concatenate_datasets(development_data)\n",
    "\n",
    "training_samples_dict = ip.split_data(\n",
    "    dataframe=full_development_dataset,\n",
    "    data_columns=[\n",
    "        \"vibration_1_magnitude\",\n",
    "        # \"vibration_2_magnitude\",\n",
    "        # \"vibration_3_magnitude\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(training_samples_dict[\"labels\"].shape)\n",
    "print(training_samples_dict[\"samples\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit dem Aufruf der Funktion `ckeck_data` werden die im vorbereiteten Datensatz enthaltenen Klassen sowie deren jeweilige Häufigkeiten überprüft, um einen Überblick über die Verteilung der verschiedenen Labels im Trainingsdatensatz zu gewinnen. Es ist wichtig eine ausgewogene Klassen-Verteilung sicherzustellen, da eine ungleiche Verteilung zu Bias und damit zu ungenauen Vorhersagen führen kann (Liu, 2025, S.36).\n",
    "Die Ausgabe von `check_data` zeigt, dass alle fünf Klassen in etwa 6430 Einträge umfassen und somit einen ausgeglichenen Querschnitt der Trainingsdaten abbilden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip.check_data(training_samples_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Das Neuronale Netz**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im nachfolgenden Codeabschnitt werden alle relevanten Parameter und Hyperparameter, die für den Aufbau und das Training des NN benötigt werden, zentral definiert. Durch die Zusammenfassung an einer Stelle bleibt der Code übersichtlicher und Anpassungen am Lernverhalten des Modells können schnell vorgenommen werden.\n",
    "\n",
    "Die Konstanten sind nach ihrer Zuständigkeit in separate Abschnitte zur Modellerstellung, Modellkompilierung und zum Training des Modells gegliedert. Abschließend werden in dem Dictionary `training_samples_dict` Gewichtungen auf die Unwuchtklassen individuell eingestellt. Im Falle einer unausgewogenen Klassenverteilung oder bei schlechter Auseinanderhaltung (s. Confusion Matrix) können Klassen-Gewichtungen das Ergebnis verbessern\n",
    "\n",
    "-> TODO bearbeiten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model creation parameters\n",
    "N_HIDDEN_LAYERS: int = 4\n",
    "L2: float = 1e-3 # 0.001\n",
    "DROPOUT: float = 0.3\n",
    "NEGATIVE_SLOPE: float = 0.3\n",
    "\n",
    "# model compilation parameters\n",
    "LEARNING_RATE: float = 1e-4\n",
    "\n",
    "# model training parameters\n",
    "BATCH_SIZE: int = 64\n",
    "EPOCHS: int = 20\n",
    "VALIDATION_SPLIT: float = 0.1\n",
    "\n",
    "# manual changes to class weights\n",
    "training_samples_dict[\"class_weights\"] = {\n",
    "    0: 0.7,  # none (Klasse 0) wird weniger stark gewichtet\n",
    "    1: 2.5,  # slight (Klasse 1) wird stärker gewichtet\n",
    "    2: 1.5,  # moderate (Klasse 2) wird leicht erhöht\n",
    "    3: 1.2,  # significant (Klasse 3) wird leicht erhöht\n",
    "    4: 0.7   # strong (Klasse 4) wird weniger stark gewichtet\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Funktion `construct_fft_net_model` wird die *Keras Sequential API* eingesetzt, um ein NN als linearen Stapel von Layern zu definieren (Keras, o.D.). Hierfür wird eine Instanz der Klasse Sequential erzeugt und mit Input-, Output- sowie der zuvor spezifizierten Anzahl Hidden Layers erweitert.\n",
    "\n",
    "Je nach Eingabeformat der Daten (1D-Struktur oder sequentielle Daten), wird dynamisch entschieden, ob eine *Fully Connected* oder eine *Convolutional* Netzwerkarchitektur erstellt wird. Im Fall eines Fully Connected Netzes werden, analog zu Mey et al (2020), 2048 Neuronen in der ersten Dense-Schicht verwendet und durch *L2-Regularisierung* sowie *Dropout* verknüpft, um Overfitting vorzubeugen (vgl. Liu, 2025, S.40f & 194).\n",
    "\n",
    "Als Aktivierungsfunktion kommt eine *LeakyReLU* mit einstellbarem *negative_slope* zum Einsatz, um das sogenannte *dying ReLU*‑Problem, also die langfristige Deaktivierung einzelner Neuronen, zu vermeiden (Adari & Alla, 2024, S.200). Abschließend wird im Output-Layer eine *Sigmoid*-Funktion genutzt, um damit das Modell auf eine Multilabel-Klassifikation anzupassen (Adari & Alla, 2024, S.203)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net.multiclass_classifier.build_model(\n",
    "    n_hidden_layers=N_HIDDEN_LAYERS,\n",
    "    training_samples_dict=training_samples_dict,\n",
    "    l2=L2,\n",
    "    dropout=DROPOUT,\n",
    "    negative_slope=NEGATIVE_SLOPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im anschließenden Schritt wird das zuvor definierte Modell mithilfe der Funktion `mc.compile_model` für das Training vorbereitet. Über den Parameter `learning_rate` wird festgelegt, wie stark die Gewichte des Netzes bei jedem Update angepasst werden (vgl. Adari & Alla, 2024, S.216), \n",
    "\n",
    "`-> auf Adam umsteigen? dann wahrscheinlich Parameter learning_rate und momentum überflüssig`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.multiclass_classifier.compile(model=model, learning_rate=LEARNING_RATE)\n",
    "\n",
    "history = net.train(\n",
    "    model=model,\n",
    "    samples_dict=training_samples_dict,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    use_early_stopping=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Bewertung des Neuronalen Netzes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize training metrics\n",
    "vis.plot_history(history, metrics=[\"loss\", \"accuracy\", \"precision\", \"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_evaluation_dataset = ip.concatenate_datasets(evaluation_data)\n",
    "\n",
    "test_samples_dict = ip.split_data(dataframe = full_evaluation_dataset, data_columns = [\n",
    "        \"vibration_1_magnitude\",\n",
    "        # \"vibration_2_magnitude\",\n",
    "        # \"vibration_3_magnitude\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip.check_data(test_samples_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "evaluation = net.evaluate(model=model, test_samples_dict=test_samples_dict, batch_size=BATCH_SIZE)\n",
    "display(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "Die Confusion Matrix zeigt, wie gut dein Modell zwischen den verschiedenen Klassen unterscheidet. Jede Zelle stellt die Anzahl der Samples dar, die einer bestimmten Klasse zugeordnet wurden (wahre Labels) und wie das Modell diese Klasse vorhergesagt hat (vorhergesagte Labels).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions by model\n",
    "true_labels, predicted_labels = net.predict(model=model, test_samples_dict=test_samples_dict)\n",
    "\n",
    "# plot confusion matrix\n",
    "vis.plot_confusion_matrix(true_labels=true_labels,\n",
    "                          predicted_labels=predicted_labels,\n",
    "                          class_names=test_samples_dict[\"encoder\"].classes_.tolist()\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Diskussion**\n",
    "- Adam optimizer könnte besser performen (Adari & Alla, S.236ff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Quellen**\n",
    "\n",
    "Liu, Z.“. (2025). Deep Learning. In: Artificial Intelligence for Engineers. Springer, Cham. https://doi.org/10.1007/978-3-031-75953-6_8\n",
    "\n",
    "Adari, S. K. & Alla, S. (2024). Beginning Anomaly Detection Using Python-Based Deep Learning. https://doi.org/10.1007/979-8-8688-0008-5\n",
    "\n",
    "Keras. (o. D.). Keras documentation: The Sequential class. https://keras.io/api/models/sequential/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
