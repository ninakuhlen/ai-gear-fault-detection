{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Projekt: Fehlererkennung in Getrieben**\n",
    "## Netztyp 2: FFT-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Vorbereitung**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# module imports from /src\n",
    "if Path.cwd().stem == \"notebooks\":\n",
    "    os.chdir( Path.cwd().parent)\n",
    "\n",
    "import src.data_loader as dl\n",
    "import src.visualization as vis\n",
    "import src.net_models as net\n",
    "import src.input_preparation as ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beispiel für ein Diagramm im Markdown\n",
    "\n",
    "```mermaid\n",
    "flowchart TD\n",
    "    Start --> Stop\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the source directory for the preprocessed data to use\n",
    "SOURCE: str = \"f2fcf2aa-bd96-4d89-8bb5-4a0a1bc11b1b\"\n",
    "\n",
    "# setup a single index for control purposes\n",
    "CONTROL_INDEX: int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup system and check the number of cpu cores and gpus available\n",
    "net.system_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Laden der Datensätze**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Üblicherweise werden für das Training eines neuronalen Netzes mittels Supervised Learning die Daten in mindestens zwei separate Datensätze aufgeteilt: einen Trainings- und einen Testdatensatz. Mit dem Testdatensatz können nach dem Training zukünftige (dem Netz unbekannte) Dateneingaben simuliert werden und so vorab die Zuverlässigkeit des Trainings beurteilt werden (Liu, 2025, S. 39).\n",
    "Nach dem Laden der Daten aus dem *data*-Ordner werden CSV-Dateien mit der Endung *D* in der Liste *development_data* und Dateien mit der Endung *E* in der Liste *evaluation_data* gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from folder and split in training and evaluation data\n",
    "data_path = Path().cwd() / \"data\" / \"processed\" / SOURCE\n",
    "development_data, evaluation_data = dl.load_all_datasets(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplarisch wird ein Datensatz aus den Development-Daten in mehreren Subplots visualisiert, um sicherzustellen, dass die Daten korrekt geladen wurden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize one random dataset for data validation\n",
    "vis.plot_column_data(development_data[CONTROL_INDEX],\n",
    "                             development_data[CONTROL_INDEX].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Vorbereitung der Daten zur Eingabe in das neuronale Netz**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um das neuronale Netz trainieren zu können, ist eine Aufbereitung der Trainings- und Testdaten erforderlich.\n",
    "Dazu werden die einzelnen DataFrames mit den Trainingsdaten zu einem einheitlichen DataFrame zusammengeführt. Gleichzeitig wird eine zusätzliche Spalte *Label* erstellt, welche die gemessenen Unwuchtstärken (*none*, *slight*, *moderate*, *significant* und *strong*) enthält und somit als *Output* für die spätere Klassifizierung dient (Liu, 2025, S.19). Die Labels werden in das One-Hot-Encoding-Format überführt, welches für die Multiklassen-Klassifizierung in Deep-Learning-Systemen benötigt wird (Liu, 2025, S.74).\n",
    "Anschließend werden die DataFrame-Spalten mit den Amplituden der Vibrationen als *Input* (Features) für das NN spezifiziert.\n",
    "\n",
    "(If Bedingung Binary Label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_development_dataset = ip.concatenate_datasets(development_data)\n",
    "\n",
    "training_samples_dict = ip.split_data(\n",
    "    dataframe=full_development_dataset,\n",
    "    data_columns=[\n",
    "        \"vibration_1_magnitude\",\n",
    "        # \"vibration_2_magnitude\",\n",
    "        # \"vibration_3_magnitude\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(training_samples_dict[\"labels\"].shape)\n",
    "print(training_samples_dict[\"samples\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit dem Aufruf der Funktion `check_data` werden die im vorbereiteten Datensatz enthaltenen Klassen sowie deren jeweilige Häufigkeiten überprüft, um einen Überblick über die Verteilung der verschiedenen Labels im Trainingsdatensatz zu gewinnen. Es ist wichtig eine ausgewogene Klassen-Verteilung sicherzustellen, da eine ungleiche Verteilung zu Bias und damit zu ungenauen Vorhersagen führen kann (Liu, 2025, S.36).\n",
    "Die Ausgabe von `check_data` zeigt, dass alle fünf Klassen in etwa 6430 Einträge umfassen und somit einen ausgeglichenen Querschnitt der Trainingsdaten abbilden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip.check_data(training_samples_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Das Neuronale Netz**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im nachfolgenden Codeabschnitt werden alle relevanten Parameter und Hyperparameter, die für den Aufbau und das Training des NN benötigt werden, zentral definiert. Durch die Zusammenfassung an einer Stelle bleibt der Code übersichtlicher und Anpassungen am Lernverhalten des Modells können schnell vorgenommen werden.\n",
    "\n",
    "Die Konstanten sind nach ihrer Zuständigkeit in separate Abschnitte zur Modellerstellung, Modellkompilierung und zum Training des Modells gegliedert. Abschließend werden in dem Dictionary `training_samples_dict` Gewichtungen auf die Unwuchtklassen individuell eingestellt. Im Falle einer unausgewogenen Klassenverteilung oder bei schlechter Auseinanderhaltung (s. Confusion Matrix) können Klassen-Gewichtungen das Ergebnis verbessern\n",
    "\n",
    "-> TODO bearbeiten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model creation parameters\n",
    "N_HIDDEN_LAYERS: int = 4\n",
    "L2: float = 1e-3 # 0.001\n",
    "DROPOUT: float = 0.3\n",
    "NEGATIVE_SLOPE: float = 0.3\n",
    "\n",
    "# model compilation parameters\n",
    "LEARNING_RATE: float = 1e-4\n",
    "\n",
    "# model training parameters\n",
    "BATCH_SIZE: int = 64\n",
    "EPOCHS: int = 20\n",
    "VALIDATION_SPLIT: float = 0.1\n",
    "\n",
    "# manual changes to class weights\n",
    "training_samples_dict[\"class_weights\"] = {\n",
    "    0: 0.7,  # none (Klasse 0) wird weniger stark gewichtet\n",
    "    1: 2.5,  # slight (Klasse 1) wird stärker gewichtet\n",
    "    2: 1.5,  # moderate (Klasse 2) wird leicht erhöht\n",
    "    3: 1.2,  # significant (Klasse 3) wird leicht erhöht\n",
    "    4: 0.7   # strong (Klasse 4) wird weniger stark gewichtet\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Funktion `construct_fft_net_model` wird die *Keras Sequential API* eingesetzt, um ein NN als linearen Stapel von Layern zu definieren (Keras, o.D.-c). Hierfür wird eine Instanz der Klasse Sequential erzeugt und mit Input-, Output- sowie der zuvor spezifizierten Anzahl Hidden Layers erweitert.\n",
    "\n",
    "Je nach Eingabeformat der Daten (1D-Struktur oder sequentielle Daten), wird dynamisch entschieden, ob eine *Fully Connected* oder eine *Convolutional* Netzwerkarchitektur erstellt wird. Im Fall eines Fully Connected Netzes werden, analog zu Mey et al (2020), 2048 Neuronen in der ersten Dense-Schicht verwendet und durch *L2-Regularisierung* sowie *Dropout* verknüpft, um Overfitting vorzubeugen (vgl. Liu, 2025, S.40f & 194).\n",
    "\n",
    "Als Aktivierungsfunktion kommt eine *LeakyReLU* mit einstellbarem *negative_slope* zum Einsatz, um das sogenannte *dying ReLU*‑Problem, also die langfristige Deaktivierung einzelner Neuronen, zu vermeiden (Adari & Alla, 2024, S.200). Abschließend wird im Output-Layer eine *Softmax*-Aktivierungsfunktion genutzt, um damit das Modell auf eine Multiklassen-Klassifikation anzupassen. Die Softmax-Funktion wird für Klassifikationsaufgaben verwendet, wo eine spezifische Klasse aus dem Input verhergesagt werden soll (Adari & Alla, 2024, S.203)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net.multiclass_classifier.build_model(\n",
    "    n_hidden_layers=N_HIDDEN_LAYERS,\n",
    "    training_samples_dict=training_samples_dict,\n",
    "    l2=L2,\n",
    "    dropout=DROPOUT,\n",
    "    negative_slope=NEGATIVE_SLOPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im anschließenden Schritt wird das zuvor definierte Modell mithilfe der Funktion `mc.compile_model` für das Training vorbereitet. Über den Parameter `learning_rate` wird festgelegt, wie stark die Gewichte des Netzes bei jedem Update angepasst werden (vgl. Adari & Alla, 2024, S.216), \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.multiclass_classifier.compile(model=model, learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Training des Modells wird mit der Funktion `train_model` aufgerufen. Dabei werden die Trainingsdaten aus dem *samples_dict*, die maximale Epochenanzahl, die *Batch-Size* und der *Validation-Split* als Parameter übergeben. Zusätzlich kann ein *Early Stopping*-Mechanismus konfiguriert werden. \n",
    "\n",
    "Early Stopping überwacht die Validierungsverluste und beendet das Training vorzeitig, wenn sich der Verlust über mehrere Epochen nicht mehr verbessert. Somit muss das Training bei suboptimal getroffenen Einstellungen des NNs nicht vollständig durchlaufen und wird vorzeitig abgebrochen. Das spart Rechenleistung und kann Overfitting vermeiden (vgl. Adari & Alla, 2024, S.225). Die Implementierung erfolgt über den EarlyStopping-Callback von Keras (Keras, o.D.-a). In der Funktion `train_model` ist EarlyStopping standardmäßig aktiviert, kann jedoch über den Parameter `use_early_stopping` bei Bedarf deaktiviert werden.\n",
    "\n",
    "Das Training selbst wird über die übergebene Anzahl von Epochen mit der Methode `model.fit` durchgeführt (Keras, o.D.-b). Der Parameter `shuffle=True` sorgt dafür, dass die Trainingsdaten vor jeder Epoche durchmischt werden, wodurch das Modell unabhängiger von der Reihenfolge der Daten wird. Mit dem Parameter `class_weight` können die Gewichtungen der einzelnen Klassen gesetzt werden, um das Training bei unausgeglichenen Datensätzen zu verbessern (Keras, o.D.-b).\n",
    "\n",
    "Am Ende gibt die Funktion ein *keras.callbacks.History*-Objekt zurück. Dieses Objekt speichert Metriken wie *Loss*, *Accuracy*, *Precision* und *Recall* über den Trainingsverlauf.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = net.train(\n",
    "    model=model,\n",
    "    samples_dict=training_samples_dict,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    use_early_stopping=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Bewertung des Neuronalen Netzes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Anschluss an das Training werden die Daten aus dem History-Objekt visualisiert. Die Funktion `plot_training_history` ermöglicht es, den Verlauf von Metriken über die Trainingsepochen hinweg grafisch darzustellen.\n",
    "Anhand der Loss Kurven von Trainings- und Validierungs-Daten lässt sich überprüfen, ob das Modell Overfitting-Verhalten aufweist. Gemäß Adari und Alla liegt ein typischer Overfitting-Fall vor, wenn das Trainings-Loss kontinuierlich sinkt, während das Validierungs-Loss ab einer gewissen Epoche beginnt zu steigen (2024, S.225). Idealerweise sollten sich beide Kurven gleichermaßen einem geringen Wert annähern. Nach dem Training mit ``X`` Epochen, nähern sich Trainings- und Validation-Loss dem Wert ``X`` an. Somit weist das Training kein Overfitting-Verhalten auf.\n",
    "\n",
    "Bezüglich Accuracy verweisen Adari und Alla darauf, dass diese zwar eine erste Aussage über die Prognosefähigkeit des Modells liefert (2024, S. 107), jedoch in vielen Fällen – insbesondere bei Klassifikationsaufgaben – nicht ausreichend aussagekräftig ist (2024, S.115). Deshalb empfiehlt Liu Precision und Recall in die Modellevaluation miteinzubeziehen (2025, S.300).\n",
    "Precision gibt den prozentualen Anteil korrekter Positivvorhersagen am Gesamtvolumen an, während Recall den Prozentsatz tatsächlich erkannter Positiver innerhalb aller Positiven beschreibt (Adari & Alla, 2024, S.116).\n",
    "\n",
    "Adari und Alla definieren die F1-Metrik als harmonischen Mittelwert von Precision und Recall, bei dem ein höherer Wert darauf hinweist, dass beide Größen vergleichsweise hoch sind (2024, S. 116). Liu beschreibt, dass ein steigender F1-Wert auf eine höhere Prognosekraft des Modells schließen lässt: Ein Wert nahe 1 deutet auf ein nahezu perfektes Klassifikationsmodell hin, während ein F1-Wert nahe 0 auf eine sehr geringe Vorhersagefähigkeit schließen lässt (2025, S. 414). Mit dem Modell dieses Projektes wird nach dem Training mit ``X`` Epochen ein Accuracy-Wert von `X` und ein F1-Wert von `X` erreicht. Dies zeigt, dass ``...``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize training metrics\n",
    "vis.plot_history(history, metrics=[\"loss\", \"accuracy\", \"precision\", \"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_evaluation_dataset = ip.concatenate_datasets(evaluation_data)\n",
    "\n",
    "test_samples_dict = ip.split_data(dataframe = full_evaluation_dataset, data_columns = [\n",
    "        \"vibration_1_magnitude\",\n",
    "        # \"vibration_2_magnitude\",\n",
    "        # \"vibration_3_magnitude\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip.check_data(test_samples_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "evaluation = net.evaluate(model=model, test_samples_dict=test_samples_dict, batch_size=BATCH_SIZE)\n",
    "display(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "Die Confusion Matrix zeigt, wie gut dein Modell zwischen den verschiedenen Klassen unterscheidet. Jede Zelle stellt die Anzahl der Samples dar, die einer bestimmten Klasse zugeordnet wurden (wahre Labels) und wie das Modell diese Klasse vorhergesagt hat (vorhergesagte Labels).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions by model\n",
    "true_labels, predicted_labels = net.predict(model=model, test_samples_dict=test_samples_dict)\n",
    "\n",
    "# plot confusion matrix\n",
    "vis.plot_confusion_matrix(true_labels=true_labels,\n",
    "                          predicted_labels=predicted_labels,\n",
    "                          class_names=test_samples_dict[\"encoder\"].classes_.tolist()\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Diskussion**\n",
    "- Adam optimizer könnte besser performen (Adari & Alla, S.236ff)\n",
    "- The tree has learned the training data exactlyincludingboththegeneralfeaturesandtheundesiredfeaturessuchas\n",
    "noise. Duetothisreason,theperformanceofatraineddecisiontreemaynotwork\n",
    "well withnewtestingdata,leadingtothepoorgeneralizationcapacityofthistype\n",
    "of algorithm.\n",
    "As illustratedinFig. 4.5, whenadecisiontreegrowsindepth,theaccuracyof\n",
    "the predictionsmadewiththetreeonthetrainingdatasetincreases,whereasthat\n",
    "on thetestingdatadecreasesasthenumberofnodesincreases.Thatmeansthetree\n",
    "gets unnecessarilycomplicatedandlearnsfeaturesspecifictothetrainingdata.This\n",
    "compromises theperformanceofthetreewhenitisappliedtothetestingdata.This\n",
    "is attributedtothefollowingfactsinthedata:\n",
    "(1) Mismeasurements:foravarietyofreasons,thevalueofanattributeorclass\n",
    "may beincorrectlymeasuredormissing.Thismayhappenbecauseofincorrect\n",
    "perception, measurement,recording,ortranscription.\n",
    "(2) Incompleteattributes:Theselectedattributesmaynotbetheperfectcriterionof\n",
    "classification. Also,itispossiblethatextraneousfactorsthatsignificantlyaffect\n",
    "the resultsarenotincludedasattributes.\n",
    "(3) Coincidence:Whenthedatasetissmall,thedatamaycoincidentallyform\n",
    "patterns thatdonotreflectgeneralrules.\n",
    "Differentmethodsareproposedtoovercomeoverfitting[54]. (Liu, S.124)\n",
    "- Area under the curve (AUC) ermitteln, um Performance des Netzes zu bestimmen "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Quellen**\n",
    "Adari, S. K. & Alla, S. (2024). Beginning Anomaly Detection Using Python-Based Deep Learning. https://doi.org/10.1007/979-8-8688-0008-5\n",
    "\n",
    "Liu, Z.“. (2025). Deep Learning. In: Artificial Intelligence for Engineers. Springer, Cham. https://doi.org/10.1007/978-3-031-75953-6_8\n",
    "\n",
    "Keras. (o. D.-a). Keras documentation: EarlyStopping. https://keras.io/api/callbacks/early_stopping/\n",
    "\n",
    "Keras. (o. D.-b). Keras documentation: Model training APIs. https://keras.io/api/models/model_training_apis/\n",
    "\n",
    "Keras. (o. D.-c). Keras documentation: The Sequential class. https://keras.io/api/models/sequential/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
