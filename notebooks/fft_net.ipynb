{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Projekt: Fehlererkennung in Getrieben**\n",
    "## Netztyp 2: FFT-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Vorbereitung**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "from uuid import uuid4\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# module imports from /src\n",
    "if Path.cwd().stem == \"notebooks\":\n",
    "    os.chdir( Path.cwd().parent)\n",
    "\n",
    "import src.data_loader as dl\n",
    "import src.visualization as vis\n",
    "import src.net_models as net\n",
    "import src.input_preparation as ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the source directory for the preprocessed data to use\n",
    "SOURCE: str = \"f2fcf2aa-bd96-4d89-8bb5-4a0a1bc11b1b\"\n",
    "\n",
    "# setup a single index for control purposes\n",
    "CONTROL_INDEX: int = 0\n",
    "\n",
    "# generate a unique identifier for this run\n",
    "UUID: str = str(uuid4())\n",
    "print(f\"Current UUID:\\t{UUID}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup system and check the number of cpu cores and gpus available\n",
    "net.system_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Laden der Datensätze**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Üblicherweise werden für das Training eines neuronalen Netzes mittels Supervised Learning die Daten in mindestens zwei separate Datensätze aufgeteilt: einen Trainings- und einen Testdatensatz. Mit dem Testdatensatz können nach dem Training zukünftige (dem Netz unbekannte) Dateneingaben simuliert werden und so vorab die Zuverlässigkeit des Trainings beurteilt werden (Liu, 2025, S. 39).\n",
    "Nach dem Laden der Daten aus dem *data*-Ordner werden CSV-Dateien mit der Endung *D* in der Liste *development_data* und Dateien mit der Endung *E* in der Liste *evaluation_data* gespeichert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from folder and split in training and evaluation data\n",
    "data_path = Path().cwd() / \"data\" / \"processed\" / SOURCE\n",
    "development_data, evaluation_data = dl.load_all_datasets(data_path)\n",
    "\n",
    "# define file path for metrics and confusion matrix\n",
    "figure_path = Path().cwd() / \"results\" / \"metrics\" / (\"m_\" + UUID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exemplarisch wird ein Datensatz aus den Development-Daten in mehreren Subplots visualisiert, um sicherzustellen, dass die Daten korrekt geladen wurden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize one random dataset for data validation\n",
    "vis.plot_column_data(development_data[CONTROL_INDEX],\n",
    "                             development_data[CONTROL_INDEX].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Vorbereitung der Daten zur Eingabe in das neuronale Netz**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um das neuronale Netz trainieren zu können, ist eine Aufbereitung der Trainings- und Testdaten erforderlich.\n",
    "Dazu werden die einzelnen DataFrames mit den Trainingsdaten zu einem einheitlichen DataFrame zusammengeführt. Gleichzeitig wird eine zusätzliche Spalte *Label* erstellt, welche die gemessenen Unwuchtstärken (*none*, *slight*, *moderate*, *significant* und *strong*) enthält und somit als *Output* für die spätere Klassifizierung dient (Liu, 2025, S.19). Die Labels werden in das One-Hot-Encoding-Format überführt, welches für die Multiklassen-Klassifizierung in Deep-Learning-Systemen benötigt wird (Liu, 2025, S.74).\n",
    "Anschließend werden die DataFrame-Spalten mit den Amplituden der Vibrationen als *Input* (Features) für das NN spezifiziert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_development_dataset = ip.concatenate_datasets(development_data)\n",
    "\n",
    "training_samples_dict = ip.split_data(\n",
    "    dataframe=full_development_dataset,\n",
    "    data_columns=[\n",
    "        \"vibration_1_magnitude\",\n",
    "        # \"vibration_2_magnitude\",\n",
    "        # \"vibration_3_magnitude\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(training_samples_dict[\"labels\"].shape)\n",
    "print(training_samples_dict[\"samples\"].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit dem Aufruf der Funktion `check_data` werden die im vorbereiteten Datensatz enthaltenen Klassen sowie deren jeweilige Häufigkeiten überprüft, um einen Überblick über die Verteilung der verschiedenen Labels im Trainingsdatensatz zu gewinnen. Es ist wichtig eine ausgewogene Klassen-Verteilung sicherzustellen, da eine ungleiche Verteilung zu Bias und damit zu ungenauen Vorhersagen führen kann (Liu, 2025, S.36).\n",
    "Die Ausgabe von `check_data` zeigt, dass alle fünf Klassen in etwa 6430 Einträge umfassen und somit einen ausgeglichenen Querschnitt der Trainingsdaten abbilden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip.check_data(training_samples_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Das Neuronale Netz**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im nachfolgenden Codeabschnitt werden alle relevanten Parameter und Hyperparameter, die für den Aufbau und das Training des NN benötigt werden, zentral definiert. Durch die Zusammenfassung an einer Stelle bleibt der Code übersichtlicher und Anpassungen am Lernverhalten des Modells können schnell vorgenommen werden.\n",
    "\n",
    "Die Konstanten sind nach ihrer Zuständigkeit in separate Abschnitte zur Modellerstellung, Modellkompilierung und zum Training des Modells gegliedert. Abschließend werden in dem Dictionary `training_samples_dict` Gewichtungen auf die Unwuchtklassen individuell eingestellt. Diese Gewichtungen können genutzt werden, wenn einzelne Klassen im Datensatz unterrepräsentiert sind oder vom Modell schlechter erkannt werden, um für eine ausgewogenere Vorhersageleistung zu sorgen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model creation parameters\n",
    "N_HIDDEN_LAYERS: int = 4\n",
    "L2: float = 1e-3 # 0.001\n",
    "DROPOUT: float = 0.3\n",
    "NEGATIVE_SLOPE: float = 0.3\n",
    "\n",
    "# model compilation parameters\n",
    "LEARNING_RATE: float = 1e-4\n",
    "\n",
    "# model training parameters\n",
    "BATCH_SIZE: int = 64\n",
    "EPOCHS: int = 1\n",
    "VALIDATION_SPLIT: float = 0.1\n",
    "\n",
    "# manual changes to class weights\n",
    "training_samples_dict[\"class_weights\"] = {\n",
    "    0: 0.7,  # none (Klasse 0) wird weniger stark gewichtet\n",
    "    1: 2.5,  # slight (Klasse 1) wird stärker gewichtet\n",
    "    2: 1.5,  # moderate (Klasse 2) wird leicht erhöht\n",
    "    3: 1.2,  # significant (Klasse 3) wird leicht erhöht\n",
    "    4: 0.7   # strong (Klasse 4) wird weniger stark gewichtet\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In der Funktion `construct_fft_net_model` wird die *Keras Sequential API* eingesetzt, um ein NN als linearen Stapel von Layern zu definieren (Keras, o.D.-c). Hierfür wird eine Instanz der Klasse Sequential erzeugt und mit Input-, Output- sowie der zuvor spezifizierten Anzahl Hidden Layers erweitert.\n",
    "\n",
    "Je nach Eingabeformat der Daten (1D-Struktur oder sequentielle Daten), wird dynamisch entschieden, ob eine *Fully Connected* oder eine *Convolutional* Netzwerkarchitektur erstellt wird. Analog zu Mey et al. umfasst das erste Dense-Layer 2048 Neuronen. In diesem Projekt ist dieses Layer um eine *L2-Regularisierung* sowie ein *Dropout* ergänzt, um Overfitting vorzubeugen (vgl. Liu, 2025, S.40f & 194).\n",
    "\n",
    "Als Aktivierungsfunktion kommt eine *LeakyReLU* mit einstellbarem *negative_slope* zum Einsatz, um das sogenannte *dying ReLU*‑Problem, also die langfristige Deaktivierung einzelner Neuronen, zu vermeiden (Adari & Alla, 2024, S.200). Abschließend wird im Output-Layer eine *Softmax*-Aktivierungsfunktion genutzt, um damit das Modell auf eine Multiklassen-Klassifikation anzupassen. Die Softmax-Funktion wird für Klassifikationsaufgaben verwendet, bei denen eine spezifische Klasse aus dem Input vorhergesagt werden soll (Adari & Alla, 2024, S.203)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = net.multiclass_classifier.build_model(\n",
    "    n_hidden_layers=N_HIDDEN_LAYERS,\n",
    "    training_samples_dict=training_samples_dict,\n",
    "    l2=L2,\n",
    "    dropout=DROPOUT,\n",
    "    negative_slope=NEGATIVE_SLOPE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im anschließenden Schritt wird das zuvor definierte Modell mithilfe der Funktion `compile` für das Training vorbereitet. Über den Parameter `learning_rate` wird festgelegt, wie stark die Gewichte des Netzes bei jedem Update angepasst werden (vgl. Adari & Alla, 2024, S.216).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.multiclass_classifier.compile(model=model, learning_rate=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Das Training des Modells wird mit der Funktion `train` aufgerufen. Dabei werden die Trainingsdaten aus dem *samples_dict*, die maximale Epochenanzahl, die *Batch-Size* und der *Validation-Split* als Parameter übergeben. Zusätzlich kann ein *Early Stopping*-Mechanismus konfiguriert werden. \n",
    "\n",
    "Early Stopping überwacht die Validierungsverluste und beendet das Training vorzeitig, wenn sich der Verlust über mehrere Epochen nicht mehr verbessert. Somit muss das Training bei suboptimal getroffenen Einstellungen des NNs nicht vollständig durchlaufen und wird vorzeitig abgebrochen. Das spart Rechenleistung und kann Overfitting vermeiden (vgl. Adari & Alla, 2024, S.225). Die Implementierung erfolgt über den EarlyStopping-Callback von Keras (Keras, o.D.-a). In der Funktion `train` ist EarlyStopping standardmäßig aktiviert, kann jedoch über den Parameter `use_early_stopping` bei Bedarf deaktiviert werden.\n",
    "\n",
    "Das Training selbst wird über die übergebene Anzahl von Epochen mit der Methode `model.fit` durchgeführt (Keras, o.D.-b). Der Parameter `shuffle=True` sorgt dafür, dass die Trainingsdaten vor jeder Epoche durchmischt werden, wodurch das Modell unabhängiger von der Reihenfolge der Daten wird. Mit dem Parameter `class_weight` können die Gewichtungen der einzelnen Klassen gesetzt werden, um das Training bei unausgeglichenen Datensätzen zu verbessern (Keras, o.D.-b).\n",
    "\n",
    "Am Ende gibt die Funktion ein *keras.callbacks.History*-Objekt zurück. Dieses Objekt speichert Metriken wie *Loss*, *Accuracy*, *Precision* und *Recall* über den Trainingsverlauf.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = net.train(\n",
    "    model=model,\n",
    "    samples_dict=training_samples_dict,\n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    use_early_stopping=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Bewertung des Neuronalen Netzes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Im Anschluss an das Training werden die Daten aus dem History-Objekt visualisiert. Die Funktion `plot_training_history` ermöglicht es, den Verlauf von Metriken über die Trainingsepochen hinweg grafisch darzustellen.\n",
    "Anhand der Loss Kurven von Trainings- und Validierungs-Daten lässt sich überprüfen, ob das Modell Overfitting-Verhalten aufweist. Gemäß Adari und Alla liegt ein typischer Overfitting-Fall vor, wenn das Trainings-Loss kontinuierlich sinkt, während das Validierungs-Loss ab einer gewissen Epoche beginnt zu steigen (2024, S.225). Idealerweise sollten sich beide Kurven gleichermaßen einem geringen Wert annähern. Nach dem Training mit 20 Epochen, nähert sich das Training-Loss dem Wert 0.2 und das Validation-Loss dem Wert 0.03 an. Die zwei Kurven liegen dicht beieinander und somit weist das Training kein Overfitting-Verhalten auf.\n",
    "\n",
    "Bezüglich Accuracy verweisen Adari und Alla darauf, dass diese zwar eine erste Aussage über die Prognosefähigkeit des Modells liefert (2024, S. 107), jedoch in vielen Fällen – insbesondere bei Klassifikationsaufgaben – nicht ausreichend aussagekräftig ist (2024, S.115). Deshalb empfiehlt Liu Precision und Recall in die Modellevaluation miteinzubeziehen (2025, S.300).\n",
    "Precision gibt den prozentualen Anteil korrekter Positivvorhersagen am Gesamtvolumen an, während Recall den Prozentsatz tatsächlich erkannter Positiver innerhalb aller Positiven beschreibt (Adari & Alla, 2024, S.116).\n",
    "\n",
    "Adari und Alla definieren die F1-Metrik als harmonischen Mittelwert von Precision und Recall, bei dem ein höherer Wert darauf hinweist, dass beide Größen vergleichsweise hoch sind (2024, S. 116). Liu beschreibt, dass ein steigender F1-Wert auf eine höhere Prognosekraft des Modells schließen lässt: Ein Wert nahe 1 deutet auf ein nahezu perfektes Klassifikationsmodell hin, während ein F1-Wert nahe 0 auf eine sehr geringe Vorhersagefähigkeit schließen lässt (2025, S. 414). Mit dem Modell dieses Projektes wird nach 20 Epochen sowohl eine Accuracy als auch ein F1-Wert von nahezu 100% mit den Trainingsdaten erreicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize training metrics\n",
    "figure_dicts = vis.plot_history(\n",
    "    history,\n",
    "    metrics=[\"accuracy\", \"f1_score\", \"loss\", \"precision\", \"recall\"],\n",
    "    separated=True,\n",
    ")\n",
    "\n",
    "\n",
    "for figure_dict in figure_dicts:\n",
    "    dl.save_figure(\n",
    "        parent_path=figure_path,\n",
    "        figure_dict=figure_dict,\n",
    "        format=\"png\",\n",
    "        dpi=300,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um das Modell auf unbekannte Daten zu testen, wird der Evaluationsdatensatz analog zur bereits beschriebenen Trainingsdaten-Aufbereitung (vgl. Abschnitt „Vorbereitung der Daten zur Eingabe in das neuronale Netz“) mithilfe der Funktionen `concatenate_datasets` und `split_data` strukturiert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_evaluation_dataset = ip.concatenate_datasets(evaluation_data)\n",
    "\n",
    "test_samples_dict = ip.split_data(dataframe = full_evaluation_dataset, data_columns = [\n",
    "        \"vibration_1_magnitude\",\n",
    "        # \"vibration_2_magnitude\",\n",
    "        # \"vibration_3_magnitude\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Folgend wird die Funktion `check_data` auf den Evaluationsdatensatz angewendet, um die vorhandenen Klassenverteilungen zu überprüfen. Aus den One-Hot-kodierten Labels wird dabei abgeleitet, wie viele Samples pro Klasse im Evaluationsdatensatz enthalten sind. Die Ausgabe zeigt, dass auch die Evaluationsdaten eine ausgeglichene Klassenverteilung mit etwa 1669 Einträgen pro Klasse aufweisen und diese dementsprechend mit den Trainingsdaten verglichen werden können. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip.check_data(test_samples_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemäß der offiziellen Dokumentation von Keras wird mithilfe der Methode `evaluate`  im Testmodus eine Vorhersage auf dem unbekannten Testdatensatz durchgeführt. Die Methode berechnet den Loss als auch die zuvor definierten Metriken (vgl. Keras, o.D.-b). Anschließend werden diese Werte in der Ausgabe angezeigt. In diesem Projekt wird `evaluate` über eine gleichnamige Wrapper-Funktion aufgerufen und erhält die Testdaten als Eingabe. Damit lässt sich untersuchen, ob das Modell – neben den guten Resultaten auf den Trainingsdaten – auch auf neuen Datensätzen eine zuverlässige Klassifikation der Unwuchtklassen liefert. Nach Adari und Alla dient dieser Evaluationsschritt als aussagekräftiger Indikator für die Wirksamkeit des Modells (2024, S.109).\n",
    "\n",
    "Die Ausgabe zeigt, dass das Modell auf den unbekannten Testdaten eine Vorhersagegenauigkeit (Accuracy) von 59% erreicht. Die Precision von rund 60% und der Recall von etwa 58% zeigen, dass das Netz sowohl bei der Identifizierung positiv eingestufter Fälle als auch bei der Reduktion falsch-negativer Entscheidungen noch Optimierungspotenzial aufweist. Der F1-Score zeigt, dass die Klassen *none* (mit rund 82%) und *strong* (mit rund 87%) eine deutlich höhere Vorhersagequalität aufzeigen, als die Klassen *slight* (mit rund 25%), *moderat* (mit rund 37%) und *significant* (mit rund 49%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "evaluation = net.evaluate(model=model, test_samples_dict=test_samples_dict, batch_size=BATCH_SIZE)\n",
    "display(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "Um die Qualität der Klassifikationsergebnisse zu prüfen wird abschließend eine Confusion Matrix erstellt. Diese baut auf den predictions der Keras `predict` Methode auf, welche Vorhersagen für die Testdaten generiert (Keras, o.D.-b). Die gleichnamige Wrapperfunktion gibt die tatsächlichen und die vorhergesagten Klassen zurück. Die Funktion `plot_confusion_matrix` erstellt eine Matrix mit den tatsächlichen Klassen in den Zeilen und den vorhergesagten Klassen in den Spalten. Auf der Diagonalen von oben links nach unten rechts sind die korrekten Vorhersagen abzulesen. Je dunkler die Farbe der Kachel ist, desto mehr Vorhersagen wurden korrekt getroffen.\n",
    "Aus der abgebildeten Matrix geht hervor, dass die Klassen *none* und *strong* am zuverlässigsten klassifiziert werden. Bei der Klasse *significant* werden die meisten Vorhersagen korrekt getroffen, jedoch treten vereinzelt Fehlklassifikationen auf. Die Klassen *moderate* und *slight* weisen hingegen mehr Fehlklassifikationen als korrekte Zuordnungen auf.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions by model\n",
    "true_labels, predicted_labels = net.predict(model=model, test_samples_dict=test_samples_dict)\n",
    "\n",
    "# plot confusion matrix\n",
    "figure_dict = vis.plot_confusion_matrix(true_labels=true_labels,\n",
    "                          predicted_labels=predicted_labels,\n",
    "                          class_names=test_samples_dict[\"encoder\"].classes_.tolist()\n",
    "                          )\n",
    "\n",
    "dl.save_figure(\n",
    "    parent_path=figure_path,\n",
    "    figure_dict=figure_dict,\n",
    "    format=\"png\",\n",
    "    dpi=300,\n",
    ")\n",
    "\n",
    "dl.save_model_hyperparameters(\n",
    "    parent_path=figure_path,\n",
    "    model=model,\n",
    "    learning_rate=LEARNING_RATE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Quellen**\n",
    "Adari, S. K. & Alla, S. (2024). Beginning Anomaly Detection Using Python-Based Deep Learning. https://doi.org/10.1007/979-8-8688-0008-5\n",
    "\n",
    "Liu, Z.“. (2025). Deep Learning. In: Artificial Intelligence for Engineers. Springer, Cham. https://doi.org/10.1007/978-3-031-75953-6_8\n",
    "\n",
    "Keras. (o. D.-a). Keras documentation: EarlyStopping. https://keras.io/api/callbacks/early_stopping/\n",
    "\n",
    "Keras. (o. D.-b). Keras documentation: Model training APIs. https://keras.io/api/models/model_training_apis/\n",
    "\n",
    "Keras. (o. D.-c). Keras documentation: The Sequential class. https://keras.io/api/models/sequential/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
