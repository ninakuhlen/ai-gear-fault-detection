{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Projekt: Fehlererkennung in Getrieben**\n",
    "## Netztyp 2: FFT-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Vorbereitung**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import os\n",
    "from pandas import DataFrame, concat\n",
    "from pathlib import Path\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# module imports from /src\n",
    "if Path.cwd().stem == \"notebooks\":\n",
    "    os.chdir( Path.cwd().parent)\n",
    "\n",
    "import src.data_loader as dl\n",
    "import src.visualization as vis\n",
    "import src.model_constructor as mc\n",
    "import src.input_preparation as ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the source directory for the preprocessed data to use\n",
    "SOURCE: str = \"c556197b-3225-45f7-8e03-68b4fb8a189d\"\n",
    "\n",
    "# setup a single index for control purposes\n",
    "CONTROL_INDEX: int = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup system and check the number of cpu cores and gpus available\n",
    "mc.system_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Laden der Datensätze**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data from folder and split in training and evaluation data\n",
    "data_path = Path().cwd() / \"data\" / \"processed\" / SOURCE\n",
    "development_data, evaluation_data = dl.load_all_datasets(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize one random dataset for data validation\n",
    "vis.plot_column_data(development_data[CONTROL_INDEX],\n",
    "                             development_data[CONTROL_INDEX].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Das Neuronale Netz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_development_dataset = ip.concatenate_datasets(development_data)\n",
    "\n",
    "training_samples_dict = ip.split_data(\n",
    "    dataframe=full_development_dataset,\n",
    "    data_columns=[\n",
    "        \"vibration_1_magnitude\",\n",
    "        # \"vibration_2_magnitude\",\n",
    "        # \"vibration_3_magnitude\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(training_samples_dict[\"labels\"].shape)\n",
    "print(training_samples_dict[\"samples\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip.check_data(training_samples_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model creation parameters\n",
    "N_HIDDEN_LAYERS: int = 4\n",
    "L2: float = 1e-3 # 0.001\n",
    "DROPOUT: float = 0.3\n",
    "NEGATIVE_SLOPE: float = 0.3\n",
    "\n",
    "# model compilation parameters\n",
    "LEARNING_RATE: float = 1e-4\n",
    "\n",
    "# model training parameters\n",
    "BATCH_SIZE: int = 64\n",
    "EPOCHS: int = 20\n",
    "VALIDATION_SPLIT: float = 0.1\n",
    "\n",
    "# manual changes to class weights\n",
    "training_samples_dict[\"class_weights\"] = {\n",
    "    0: 0.7,  # none (Klasse 0) wird weniger stark gewichtet\n",
    "    1: 2.5,  # slight (Klasse 1) wird stärker gewichtet\n",
    "    2: 1.5,  # moderate (Klasse 2) wird leicht erhöht\n",
    "    3: 1.2,  # significant (Klasse 3) bleibt gleich\n",
    "    4: 0.7   # strong (Klasse 4) wird weniger stark gewichtet\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mc.construct_fft_net_model(n_hidden_layers=N_HIDDEN_LAYERS,\n",
    "                                   training_samples_dict=training_samples_dict,\n",
    "                                   l2=L2,\n",
    "                                   dropout=DROPOUT,\n",
    "                                   negative_slope=NEGATIVE_SLOPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mc.compile_model(model=model,\n",
    "                 learning_rate=LEARNING_RATE)\n",
    "\n",
    "\n",
    "history = mc.train_model(model=model,\n",
    "                         samples_dict=training_samples_dict,\n",
    "                         epochs=EPOCHS,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         validation_split=VALIDATION_SPLIT,\n",
    "                         use_early_stopping=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Bewertung des Neuronalen Netzes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize training metrics\n",
    "vis.plot_history(history, metrics=[\"loss\", \"accuracy\", \"precision\", \"recall\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_evaluation_dataset = ip.concatenate_datasets(evaluation_data)\n",
    "\n",
    "test_samples_dict = ip.split_data(dataframe = full_evaluation_dataset, data_columns = [\n",
    "        \"vibration_1_magnitude\",\n",
    "        # \"vibration_2_magnitude\",\n",
    "        # \"vibration_3_magnitude\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "print(test_samples_dict[\"labels\"].shape)\n",
    "print(test_samples_dict[\"samples\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ip.check_data(test_samples_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate model\n",
    "evaluation = mc.evaluate(model=model, test_samples_dict=test_samples_dict)\n",
    "display(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix\n",
    "Die Confusion Matrix zeigt, wie gut dein Modell zwischen den verschiedenen Klassen unterscheidet. Jede Zelle stellt die Anzahl der Samples dar, die einer bestimmten Klasse zugeordnet wurden (wahre Labels) und wie das Modell diese Klasse vorhergesagt hat (vorhergesagte Labels).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions by model\n",
    "true_labels, predicted_labels = mc.predict(model=model, test_samples_dict=test_samples_dict)\n",
    "\n",
    "print(type(test_samples_dict[\"encoder\"].classes_))\n",
    "\n",
    "# plot confusion matrix\n",
    "vis.plot_confusion_matrix(true_labels=true_labels,\n",
    "                          predicted_labels=predicted_labels,\n",
    "                          class_names=test_samples_dict[\"encoder\"].classes_.tolist()\n",
    "                          )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
